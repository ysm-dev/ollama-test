name: Ollama

on:
  workflow_dispatch:

jobs:
  ollama:
    runs-on: ubuntu-latest
    steps:
      - name: Install ollama
        run: curl -fsSL https://ollama.com/install.sh | sh
      - name: Run ollama
        run: |
          ollama serve &
          ollama pull llama3.3

      - name: Call ollama API
        run: |
          curl -d '{"model": "llama3.3", "stream": false, "prompt":"Who are you? What is your model name?"}' http://localhost:11434/api/generate
